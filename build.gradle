plugins {
  id 'java'
  id 'net.saliman.properties' version '1.5.2'
  id 'com.gradleup.shadow' version '8.3.4'

  // Only used for testing
  id 'jacoco'
  id "org.sonarqube" version "5.1.0.4882"

  // Used to generate Avro classes. This will write classes to build/generated-test-avro-java and also add that folder
  // as a source root. Since this is commented out by default, the generated Avro test class has been added to
  // src/test/java. This only needs to be uncommented when there's a need to regenerate that class, at which point it
  // should be copied over to src/test/java and then this plugin should be commented out again.
  // id "com.github.davidmc24.gradle.plugin.avro" version "1.6.0"
}

java {
  sourceCompatibility = 1.8
  targetCompatibility = 1.8
}

repositories {
  mavenCentral()
}

configurations {
  documentation
  assets

  // Force v3.18 of commons-lang3 to avoid security vulnerabilities, without also
  // upgrading ml-app-deployer to 6.0.0, which we are not ready to do yet.
  configurations.all {
    resolutionStrategy {
        force 'org.apache.commons:commons-lang3:3.18.0'
    }
  }
}

ext {
  kafkaVersion = "3.8.1"
}

dependencies {
  compileOnly "org.apache.kafka:connect-runtime:${kafkaVersion}"
  compileOnly "org.slf4j:slf4j-api:1.7.36"

  // Force DHF to use the latest version of ml-app-deployer, which minimizes security vulnerabilities
  implementation "com.marklogic:ml-app-deployer:5.0.0"

  implementation "com.fasterxml.jackson.dataformat:jackson-dataformat-csv:2.17.2"

  // Note that in general, the version of the DHF jar must match that of the deployed DHF instance. Different versions
  // may work together, but that behavior is not guaranteed.
  implementation("com.marklogic:marklogic-data-hub:6.1.1") {
    exclude module: "marklogic-client-api"
    exclude module: "ml-javaclient-util"
    exclude module: "ml-app-deployer"

    // No need for mlcp-util, it's only used in 'legacy' DHF 4 jobs
    exclude module: "mlcp-util"
    // Excluding because it causes Kafka Connect to complain mightily if included
    exclude module: "logback-classic"
  }

  testImplementation 'com.marklogic:marklogic-junit5:1.5.0'

  testImplementation "org.apache.kafka:connect-json:${kafkaVersion}"

  // Can be deleted when the disabled kafka-junit tests are deleted.
  testImplementation 'net.mguenther.kafka:kafka-junit:3.6.0'

  testImplementation "org.apache.avro:avro-compiler:1.12.0"

  // Forcing logback to be used for test logging
  testImplementation "ch.qos.logback:logback-classic:1.3.14"
  testImplementation "org.slf4j:jcl-over-slf4j:2.0.16"

  documentation files('LICENSE.txt')
  documentation files('NOTICE.txt')
  documentation files('README.md')

  assets files('MarkLogic_logo.png')
  assets files('apache_logo.png')
}

// This ensures that the compiler reports "unchecked" warnings.
// This helps us use the compiler to prevent potential problems.
tasks.withType(JavaCompile) {
  options.compilerArgs << '-Xlint:unchecked'
  options.deprecation = true
}

test {
  useJUnitPlatform()
}

// Configures jacoco test coverage to be included when "test" is run
test {
  finalizedBy jacocoTestReport
}
jacocoTestReport {
  dependsOn test
}
// Enabling the XML report allows for sonar to grab coverage data from jacoco
jacocoTestReport {
  reports {
    // This isn't working with Gradle 8. Will replace this soon with the sonar instance in docker-compose.
    // xml.enabled true
  }
}


shadowJar {
  // Exclude DHF source files
  exclude "hub-internal-artifacts/**"
  exclude "hub-internal-config/**"
  exclude "ml-config/**"
  exclude "ml-modules*/**"
  exclude "scaffolding/**"
}

ext {
  confluentArchiveGroup = "Confluent Connector Archive"
  confluentTestingGroup = "Confluent Platform Local Testing"
  baseArchiveBuildDir = "build/connectorArchive"
  baseArchiveName = "${componentOwner}-${componentName}-${version}"
}

// Tasks for building the archive required for submitting to the Confluence Connector Hub

import org.apache.tools.ant.filters.ReplaceTokens

task connectorArchive_CopyManifestToBuildDirectory(type: Copy, group: confluentArchiveGroup) {
  description = "Copy the project manifest into the root folder"
  from '.'
  include 'manifest.json'
  into "${baseArchiveBuildDir}/${baseArchiveName}"
  filter(ReplaceTokens, tokens: [CONFLUENT_USER: componentOwner, VERSION: version])
}

task connectorArchive_CopyAssetsToBuildDirectory(type: Copy, group: confluentArchiveGroup) {
  description = "Copy the project assets into the assets folder"
  from configurations.assets
  into "${baseArchiveBuildDir}/${baseArchiveName}/assets"
}

task connectorArchive_CopyEtcToBuildDirectory(type: Copy, group: confluentArchiveGroup) {
  description = "Copy the project support files into the etc folder"
  from 'config'
  include '*'
  into "${baseArchiveBuildDir}/${baseArchiveName}/etc"
}

task connectorArchive_CopyDocumentationToBuildDirectory(type: Copy, group: confluentArchiveGroup) {
  description = "Copy the project documentation into the doc folder"
  from configurations.documentation
  into "${baseArchiveBuildDir}/${baseArchiveName}/doc"
}

task connectorArchive_CopyDependenciesToBuildDirectory(type: Copy, group: confluentArchiveGroup, dependsOn: jar) {
  description = "Copy the dependency jars into the lib folder"
  from jar
  // Confluent already includes the Jackson dependencies that this connector depends on. If the connector includes any
  // itself, and the DHF integration is used with the sink connector, then the following error will occur when DHF
  // tries to connect to the Manage API of MarkLogic:
  // java.lang.ClassCastException: com.fasterxml.jackson.datatype.jdk8.Jdk8Module cannot be cast to com.fasterxml.jackson.databind.Module
  //	at org.springframework.http.converter.json.Jackson2ObjectMapperBuilder.registerWellKnownModulesIfAvailable(Jackson2ObjectMapperBuilder.java:849)
  // stackoverflow indicates this may be due to multiple copies of Jackson being on the classpath, as Jdk8Module
  // otherwise should be castable to Module.
  // Testing has verified that excluding all "jackson-" jars still results in the connector working properly with
  // Confluent 7.3.1. This has no impact on using the connector with plain Apache Kafka which does not rely on
  // constructing this connector archive.
  from configurations.runtimeClasspath.findAll { it.name.endsWith('jar') && !it.name.startsWith("jackson-")}
  into "${baseArchiveBuildDir}/${baseArchiveName}/lib"
}

task connectorArchive_BuildDirectory(group: confluentArchiveGroup) {
  description = "Build the directory that will be used to create the Kafka Connector Archive"
  dependsOn = [
    connectorArchive_CopyManifestToBuildDirectory,
    connectorArchive_CopyDependenciesToBuildDirectory,
    connectorArchive_CopyDocumentationToBuildDirectory,
    connectorArchive_CopyEtcToBuildDirectory,
    connectorArchive_CopyAssetsToBuildDirectory
  ]
}

task connectorArchive(type: Zip, dependsOn: connectorArchive_BuildDirectory, group: confluentArchiveGroup) {
  description = 'Build a Connector Hub for the Confluent Connector Hub'
  from "${baseArchiveBuildDir}"
  include '**/*'
  archiveFileName = "${baseArchiveName}.zip"
  destinationDirectory = file('build/distro')
}

// Tasks for using the connector with Confluent Platform on Docker

task copyConnectorToDockerVolume(type: Copy, dependsOn: connectorArchive, group: confluentTestingGroup) {
  description = "Copies the connector's archive directory to the Docker volume shared with the Connect server"
  from "build/connectorArchive"
  into "test-app/docker/confluent-marklogic-components"
}
