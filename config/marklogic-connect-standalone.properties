# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# These are defaults. This file just demonstrates how to override some settings.
bootstrap.servers=localhost:9092


# The next two sections are necessary to establish an SSL connection to the Kafka servers.
# To enable SSL, uncomment and customize the lines that start with "#* " in those two sections.

# SSL connection properties
# For more information, see https://docs.confluent.io/current/kafka/encryption.html#encryption-ssl-connect
#   These top-level settings are used by the Connect worker for group coordination and to read and write to the internal
#   topics which are used to track the cluster's state (e.g. configs and offsets).
#* security.protocol=SSL
# You must create a truststore that contains either the server certificate or a trusted CA that signed the server cert.
# This is how I did it with keytools:
#   keytool -keystore kafka.truststore.jks -alias caroot -import -file ca-cert -storepass "XXXXX" -keypass "XXXXX" -noprompt
#* ssl.truststore.location=/secure/path/to/certs/kafka.client.truststore.jks
#* ssl.truststore.password=truststorePassphrase
# For now, turn off hostname verification since we're using self-signed certificates
# This might also be fixable by fixing the "Subject Alternative Name (SAN)", but I'm not a cert expert.
#* ssl.endpoint.identification.algorithm=

# Yes, both of these sections are required.
#   Connect workers manage the producers used by source connectors and the consumers used by sink connectors.
#   So, for the connectors to leverage security, you also have to override the default producer/consumer
#   configuration that the worker uses.
#* consumer.bootstrap.servers=localhost:9093
#* consumer.security.protocol=SSL
#* consumer.ssl.truststore.location=/secure/path/to/certs/kafka.client.truststore.jks
#* consumer.ssl.truststore.password=truststorePassphrase
#* consumer.ssl.endpoint.identification.algorithm=


# The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will
# need to configure these based on the format they want their data in when loaded from or stored into Kafka

# Set the converters to the JsonConverter for JSON
#key.converter=org.apache.kafka.connect.json.JsonConverter
#value.converter=org.apache.kafka.connect.json.JsonConverter

# Set the converters to the StringConverter for XML
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter


# Converter-specific settings can be passed in by prefixing the Converter's setting with the converter we want to apply
# it to
key.converter.schemas.enable=false
value.converter.schemas.enable=false

offset.storage.file.filename=/tmp/connect.offsets
# Flush much faster than normal, which is useful for testing/debugging
offset.flush.interval.ms=10000

# Set to a list of filesystem paths separated by commas (,) to enable class loading isolation for plugins
# (connectors, converters, transformations). The list should consist of top level directories that include 
# any combination of: 
# a) directories immediately containing jars with plugins and their dependencies
# b) uber-jars with plugins and their dependencies
# c) directories immediately containing the package directory structure of classes of plugins and their dependencies
# Note: symlinks will be followed to discover dependencies or plugins.
# Examples: 
# plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins,/opt/connectors,
#plugin.path=
